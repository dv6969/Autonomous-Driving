#steering control using waypoint
#using normalize vector calculation
import carla
import random
import cv2
import numpy as np
import time
import math
import open3d as o3d
from matplotlib import cm
import sys


# Connect to the CARLA server
client = carla.Client('localhost', 2000)
client.set_timeout(10.0)

#steer control in carla
#create a control fuction so that we can drive the car along the route

prefer_speed = 35
s_threshold = 2 #when we get colse to desired speed we drop the speed

#adding params to display text to image
font = cv2.FONT_HERSHEY_SIMPLEX

#org-> defining the line to display the telemetry value on the screen

org=(30, 30) #used to show the current speed 
org2=(30, 50)#used for future steering angle
org3=(30, 70)#line for future telemetry output
org4=(30, 90)#line for suture telemetry output
org5=(30, 110)#line for suture telemetry output
fontScale = 0.5

color = (255, 255, 0) #white color

thickness = 1 #line thickness

def maintain_speed(s):
    ''' this function is to maintain the desired speed '''
    
    if s >= prefer_speed:
        return 0
    elif s < prefer_speed - s_threshold:
        return 0.8 #give a 0.8 bit of gas means pressure on acclerator
    else:
        return 0.4
    
def angle_between(v1, v2):
    return math.degrees(np.arctan2(v1[1], v1[0]) - np.arctan2(v2[1], v2[0]))


def get_angle(car,wp):
    
    vehicle_pos=car.get_transform()
    car_x=vehicle_pos.location.x
    car_y=vehicle_pos.location.y
    wp_x=wp.transform.location.x
    wp_y=wp.transform.location.y
    
    x= (wp_x - car_x)/((wp_y - car_y)**2 + (wp_x - car_x)**2)**0.5
    y= (wp_y - car_y)/((wp_y - car_y)**2 + (wp_x - car_x)**2)**0.5
    
    
    car_vector = vehicle_pos.get_forward_vector()
    degrees = angle_between((x,y),(car_vector.x,car_vector.y))
    print(degrees)
    return degrees

world = client.get_world()
#bp_lib=world.get_blueprint_library()
spawn_points = world.get_map().get_spawn_points()
if not spawn_points:
    raise ValueError("No spawn points available.")
start_point = spawn_points[0]

vehicle_bp=world.get_blueprint_library().filter('*dodge*')

if vehicle_bp is None:
    raise ValueError("Vehicle blueprint not found.")


vehicle = world.try_spawn_actor(vehicle_bp[0], start_point)
if vehicle is None:
    raise ValueError("Failed to spawn the vehicle.")

sys.path.append('C:\Program Files (x86)\Carla-0.10.0-Win64-Shipping\PythonAPI\carla')
from agents.navigation.global_route_planner import GlobalRoutePlanner
town_map = world.get_map()
sampling_resolution = 1
grp = GlobalRoutePlanner(town_map,sampling_resolution)

point_a = start_point.location
#to check the longest possible route

distance = 0

for loc in spawn_points:
    cur_route = grp.trace_route(point_a, loc.location)
    if len(cur_route)>distance:
        distance = len(cur_route)
        route = cur_route
        


for waypoint in route:
    #color = carla.Color(r=255,g=0,b=0)
    world.debug.draw_string(waypoint[0].transform.location, '^', draw_shadow=False,life_time=600.0)
    #color = carla.Color(r=255,g=0,b=0)


#setting up rgb camera 
#camera mount offset on the car

CAMERA_POS_Z = 1.6 #means 1.6m up from the ground
CAMERA_POS_X = 0.9 #this means 0.9m forward 

camera_bp=world.get_blueprint_library().find('sensor.camera.rgb')
camera_bp.set_attribute('image_size_x', '640')#640 pixel wide
camera_bp.set_attribute('image_size_y', '360')#360PIXEL TALL

camera_init_trans = carla.Transform(carla.Location(z=CAMERA_POS_Z,x=CAMERA_POS_X))
#this create camera in sim
camera = world.spawn_actor(camera_bp,camera_init_trans,attach_to=vehicle)


def camera_callback(image,data_dict):
    data_dict['image'] = np.reshape(np.copy(image.raw_data),(image.height,image.width,4))
    
image_w = camera_bp.get_attribute('image_size_x').as_int()
image_h = camera_bp.get_attribute('image_size_y').as_int()

camera_data = {'image': np.zeros((image_h,image_w,4))}

#open the live stream from camrea

camera.listen(lambda image: camera_callback(image,camera_data))


#spectator = world.get_spectator()
#spawn_points = world.get_map().get_spawn_points()
#startpoint = spawn_points[0]

#spectator_pos = carla.Transform(start_point.location + carla.Location(x=16,y=9,z=2),
#                               carla.Rotation(yaw = start_point.rotation.yaw -155))

#spectator.set_transform(spectator_pos)


cv2.namedWindow('RGB Camera', cv2.WINDOW_AUTOSIZE)
cv2.imshow('RGB Camera',camera_data['image'])


quit = False
curr_wp = 5#tracking the waypoint

predicted_angle = 0
while curr_wp<len(route)-1:
    world.tick()
    if cv2.waitKey(1) == ord('q'):
        quit = True
        vehicle.apply_control(carla.VehicleControl(throttle = 0, steer = 0, brake = 1))
        break
    image = camera_data['image']
    
    while curr_wp<len(route) and vehicle.get_transform().location.distance(route[curr_wp][0].transform.location)<5:
        curr_wp +=1
    
    predicted_angle=get_angle(vehicle,route[curr_wp][0])
    print(predicted_angle)
    image = cv2.putText(image, 'Steering angle:'+str(round(predicted_angle,3)), org,
                                           font, fontScale, color, thickness, cv2.LINE_AA)
    v=vehicle.get_velocity()
    speed = round(3.6 * math.sqrt(v.x**2 + v.y**2 + v.z**2),0)
    #add speed to the window showing a camera mounted on the car
    image = cv2.putText(image, 'Speed:'+str(int(speed))+' kmh', org2,
                                           font, fontScale, color, thickness, cv2.LINE_AA)

    image = cv2.putText(image, 'Next wp:'+str(int(curr_wp)), org3,
                                           font, fontScale, color, thickness, cv2.LINE_AA)
    estimated_throttle = maintain_speed(speed)
    
    
    if predicted_angle<-300:
        predicted_angle=predicted_angle+360
    elif predicted_angle>300:
        predicted_angle=predicted_angle-360
    steer_input = predicted_angle
    #conversion of -1 to +1
    if predicted_angle<-40:
        steer_input= -40
    elif predicted_angle>40:
        steer_input = 40
    #sonversion to apply control to car 
    
    steer_input=steer_input/35
    print(steer_input)
    vehicle.apply_control(carla.VehicleControl(throttle = estimated_throttle, steer = steer_input))
    cv2.imshow('RGB Camera',image)
    

#cleanup

cv2.destroyAllWindows()
camera.stop()
for sensor in world.get_actors().filter('*sensor*'):
    sensor.destroy()
vehicle.apply_control(carla.VehicleControl(throttle = 0, steer = 0, brake = 1))